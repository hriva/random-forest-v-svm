{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phishing Email Detection.\n",
    "\n",
    "A comparison on Random Forest vs Supor Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest data set.\n",
    "> Download from https://www.kaggle.com/datasets/subhajournal/phishingemails/download?datasetVersionNumber=1\n",
    "\n",
    "**SEE REAMDE.md** on instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18650 entries, 0 to 18649\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  18650 non-null  int64 \n",
      " 1   Email Text  18634 non-null  object\n",
      " 2   Email Type  18650 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 437.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Ingest\n",
    "## Make pandas read the data.\n",
    "pd.options.mode.copy_on_write = True\n",
    "data = pd.read_csv(\"data/Phishing_Email.csv\")\n",
    "data.shape, data.columns\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove NA's\n",
    "Remove partially filled rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrangle\n",
    "data.isna().sum()  # List empty variables\n",
    "df = data.dropna() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check classes balance\n",
    "Check for observation balance in the sample. If the sample is unbalanced the model might learn to predict the observations with bigger pools better thant the smaller ones and bin the predictions towards these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check sample balance\n",
    "## DONT FORGET TO ADD .to_frame LEST you know how to operate pandas.Series\n",
    "base_lines = df[\"Email Type\"].value_counts().to_frame()  # Sample is IMBALANCED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, the samples with the biggest pools were undersampled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding Weights & undersampling\n",
    "base_lines[\"weights\"] = base_lines[\"count\"] / base_lines[\"count\"].max()\n",
    "undersample_obs = base_lines[\"count\"].min()\n",
    "oversampled = df[df[\"Email Type\"] == \"Safe Email\"].sample(undersample_obs)\n",
    "dfx = pd.concat(\n",
    "    [oversampled, df[df[\"Email Type\"] == \"Phishing Email\"]], ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in train, test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train test\n",
    "X = dfx[\"Email Text\"]  # Features\n",
    "y = dfx[\"Email Type\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of creating a function to convert each text observation into a vector of words manually and then iterate over each one of the observations. Scikit learn provides a method for doing this and chaining it with the ML algorithm as a pipe line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "classifier = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", TfidfVectorizer()),\n",
    "        (\"classifier\", RandomForestClassifier(n_estimators=10)),\n",
    "    ]\n",
    ")\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you would like to see what vectorizer is doing. You can create the following block** \n",
    "```python\n",
    "vectorizer = TfidfVectorizer( encoding='utf-8')  \n",
    "x = vectorizer.fit_transform(X_train)  # This pases the whole array for demonstration.\n",
    "vectorizer.get_feature_names_out()\n",
    "```\n",
    "\n",
    "Do note that vectorizer is not tokenizing the text information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9312820512820513\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Phishing Email       0.91      0.96      0.93      1468\n",
      "    Safe Email       0.96      0.90      0.93      1457\n",
      "\n",
      "      accuracy                           0.93      2925\n",
      "     macro avg       0.93      0.93      0.93      2925\n",
      "  weighted avg       0.93      0.93      0.93      2925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "y_hat = classifier.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, y_hat)\n",
    "print(metrics.classification_report(y_test, y_hat))\n",
    "print(\"\\nAccuracy:\", metrics.accuracy_score(y_test, y_hat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suport Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "SVM = Pipeline([(\"vectorizer\", TfidfVectorizer()), (\"SVM\", SVC(C=100, gamma=\"auto\"))])\n",
    "SVM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Phishing Email       0.00      0.00      0.00      1468\n",
      "    Safe Email       0.50      1.00      0.66      1457\n",
      "\n",
      "      accuracy                           0.50      2925\n",
      "     macro avg       0.25      0.50      0.33      2925\n",
      "  weighted avg       0.25      0.50      0.33      2925\n",
      "\n",
      "\n",
      "Accuracy: 0.49811965811965814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alquimista/Code/.devel-env/lib64/python3.12/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/alquimista/Code/.devel-env/lib64/python3.12/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/alquimista/Code/.devel-env/lib64/python3.12/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate svm\n",
    "svm_y_hat = SVM.predict(X_test)\n",
    "metrics.confusion_matrix(y_test, svm_y_hat)\n",
    "print(metrics.classification_report(y_test, svm_y_hat))\n",
    "print(\"\\nAccuracy:\", metrics.accuracy_score(y_test, svm_y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".devel-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
